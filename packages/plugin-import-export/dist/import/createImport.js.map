{"version":3,"sources":["../../src/import/createImport.ts"],"sourcesContent":["import type { PayloadRequest, TypedUser } from 'payload'\n\nimport { APIError } from 'payload'\n\nimport { getImportFieldFunctions } from '../utilities/getImportFieldFunctions.js'\nimport { parseCSV } from '../utilities/parseCSV.js'\nimport { parseJSON } from '../utilities/parseJSON.js'\nimport { removeDisabledFields } from '../utilities/removeDisabledFields.js'\nimport { unflattenObject } from '../utilities/unflattenObject.js'\nimport { createImportBatchProcessor } from './batchProcessor.js'\n\nexport type ImportMode = 'create' | 'update' | 'upsert'\n\nexport type Import = {\n  /**\n   * Number of documents to process in each batch during import\n   * @default 100\n   */\n  batchSize?: number\n  collectionSlug: string\n  /**\n   * If true, enabled debug logging\n   */\n  debug?: boolean\n  file?: {\n    data: Buffer\n    mimetype: string\n    name: string\n  }\n  format: 'csv' | 'json'\n  id?: number | string\n  /**\n   * Import mode: create, update or upset\n   */\n  importMode: ImportMode\n  matchField?: string\n  name: string\n  userCollection?: string\n  userID?: number | string\n}\n\nexport type CreateImportArgs = {\n  defaultVersionStatus?: 'draft' | 'published'\n  req: PayloadRequest\n} & Import\n\nexport type ImportResult = {\n  errors: Array<{\n    doc: Record<string, unknown>\n    error: string\n    index: number\n  }>\n  imported: number\n  total: number\n  updated: number\n}\n\nexport const createImport = async ({\n  batchSize = 100,\n  collectionSlug,\n  debug = false,\n  defaultVersionStatus = 'published',\n  file,\n  format,\n  importMode = 'create',\n  matchField = 'id',\n  req,\n  userCollection,\n  userID,\n}: CreateImportArgs): Promise<ImportResult> => {\n  let user: TypedUser | undefined\n\n  if (userCollection && userID) {\n    user = (await req.payload.findByID({\n      id: userID,\n      collection: userCollection,\n    })) as TypedUser\n  }\n\n  if (!user) {\n    throw new APIError('User is required for import operations', 401, null, true)\n  }\n\n  if (debug) {\n    req.payload.logger.debug({\n      collectionSlug,\n      format,\n      importMode,\n      matchField,\n      message: 'Starting import process with args:',\n      transactionID: req.transactionID, // Log transaction ID to verify we're in same transaction\n    })\n  }\n\n  if (!collectionSlug) {\n    throw new APIError('Collection slug is required', 400, null, true)\n  }\n\n  if (!file || !file?.data) {\n    throw new APIError('No file data provided for import', 400, null, true)\n  }\n\n  if (debug) {\n    req.payload.logger.debug({\n      fileName: file.name,\n      fileSize: file.data.length,\n      message: 'File info',\n      mimeType: file.mimetype,\n    })\n  }\n\n  const collectionConfig = req.payload.config.collections.find(\n    ({ slug }) => slug === collectionSlug,\n  )\n\n  if (!collectionConfig) {\n    if (!collectionSlug) {\n      throw new APIError('Collection slug is required', 400, null, true)\n    }\n    throw new APIError(`Collection with slug ${collectionSlug} not found`, 400, null, true)\n  }\n\n  // Get disabled fields configuration\n  const disabledFields =\n    collectionConfig.admin?.custom?.['plugin-import-export']?.disabledFields ?? []\n\n  // Get fromCSV functions for field transformations\n  const fromCSVFunctions = getImportFieldFunctions({\n    fields: collectionConfig.flattenedFields || [],\n  })\n\n  // Parse the file data\n  let documents: Record<string, unknown>[]\n  if (format === 'csv') {\n    const rawData = await parseCSV({\n      data: file.data,\n      req,\n    })\n\n    // Debug logging\n    if (debug && rawData.length > 0) {\n      req.payload.logger.info({\n        firstRow: rawData[0], // Show the complete first row\n        msg: 'Parsed CSV data - FULL',\n      })\n      req.payload.logger.info({\n        msg: 'Parsed CSV data',\n        rows: rawData.map((row, i) => ({\n          excerpt: row.excerpt,\n          hasManyNumber: row.hasManyNumber, // Add this to see what we get from CSV\n          hasOnePolymorphic_id: row.hasOnePolymorphic_id,\n          hasOnePolymorphic_relationTo: row.hasOnePolymorphic_relationTo,\n          index: i,\n          title: row.title,\n        })),\n      })\n    }\n\n    documents = rawData\n\n    // Unflatten CSV data\n    documents = documents\n      .map((doc) => {\n        const unflattened = unflattenObject({\n          data: doc,\n          fields: collectionConfig.flattenedFields ?? [],\n          fromCSVFunctions,\n          req,\n        })\n        return unflattened ?? {}\n      })\n      .filter((doc) => doc && Object.keys(doc).length > 0)\n\n    // Debug after unflatten\n    if (debug && documents.length > 0) {\n      req.payload.logger.info({\n        msg: 'After unflatten',\n        rows: documents.map((row, i) => ({\n          hasManyNumber: row.hasManyNumber, // Add this to see the actual value\n          hasManyPolymorphic: row.hasManyPolymorphic,\n          hasOnePolymorphic: row.hasOnePolymorphic,\n          hasTitle: 'title' in row,\n          index: i,\n          title: row.title,\n        })),\n      })\n    }\n\n    if (debug) {\n      req.payload.logger.debug({\n        documentCount: documents.length,\n        message: 'After unflattening CSV',\n        rawDataCount: rawData.length,\n      })\n\n      // Debug: show a sample of raw vs unflattened\n      if (rawData.length > 0 && documents.length > 0) {\n        req.payload.logger.debug({\n          message: 'Sample data transformation',\n          raw: Object.keys(rawData[0] || {}).filter((k) => k.includes('localized')),\n          unflattened: JSON.stringify(documents[0], null, 2),\n        })\n      }\n    }\n  } else {\n    documents = parseJSON({ data: file.data, req })\n  }\n\n  if (debug) {\n    req.payload.logger.debug({\n      message: `Parsed ${documents.length} documents from ${format} file`,\n    })\n    if (documents.length > 0) {\n      req.payload.logger.debug({\n        doc: documents[0],\n        message: 'First document sample:',\n      })\n    }\n  }\n\n  // Remove disabled fields from all documents\n  if (disabledFields.length > 0) {\n    documents = documents.map((doc) => removeDisabledFields(doc, disabledFields))\n  }\n\n  if (debug) {\n    req.payload.logger.debug({\n      batchSize,\n      documentCount: documents.length,\n      message: 'Processing import in batches',\n    })\n  }\n\n  // Create batch processor\n  const processor = createImportBatchProcessor({\n    batchSize,\n    defaultVersionStatus,\n  })\n\n  // Process import with batch processor\n  const result = await processor.processImport({\n    collectionSlug,\n    documents,\n    importMode,\n    matchField,\n    req,\n    user,\n  })\n\n  if (debug) {\n    req.payload.logger.info({\n      errors: result.errors.length,\n      imported: result.imported,\n      message: 'Import completed',\n      total: result.total,\n      updated: result.updated,\n    })\n  }\n\n  return result\n}\n"],"names":["APIError","getImportFieldFunctions","parseCSV","parseJSON","removeDisabledFields","unflattenObject","createImportBatchProcessor","createImport","batchSize","collectionSlug","debug","defaultVersionStatus","file","format","importMode","matchField","req","userCollection","userID","user","payload","findByID","id","collection","logger","message","transactionID","data","fileName","name","fileSize","length","mimeType","mimetype","collectionConfig","config","collections","find","slug","disabledFields","admin","custom","fromCSVFunctions","fields","flattenedFields","documents","rawData","info","firstRow","msg","rows","map","row","i","excerpt","hasManyNumber","hasOnePolymorphic_id","hasOnePolymorphic_relationTo","index","title","doc","unflattened","filter","Object","keys","hasManyPolymorphic","hasOnePolymorphic","hasTitle","documentCount","rawDataCount","raw","k","includes","JSON","stringify","processor","result","processImport","errors","imported","total","updated"],"mappings":"AAEA,SAASA,QAAQ,QAAQ,UAAS;AAElC,SAASC,uBAAuB,QAAQ,0CAAyC;AACjF,SAASC,QAAQ,QAAQ,2BAA0B;AACnD,SAASC,SAAS,QAAQ,4BAA2B;AACrD,SAASC,oBAAoB,QAAQ,uCAAsC;AAC3E,SAASC,eAAe,QAAQ,kCAAiC;AACjE,SAASC,0BAA0B,QAAQ,sBAAqB;AAgDhE,OAAO,MAAMC,eAAe,OAAO,EACjCC,YAAY,GAAG,EACfC,cAAc,EACdC,QAAQ,KAAK,EACbC,uBAAuB,WAAW,EAClCC,IAAI,EACJC,MAAM,EACNC,aAAa,QAAQ,EACrBC,aAAa,IAAI,EACjBC,GAAG,EACHC,cAAc,EACdC,MAAM,EACW;IACjB,IAAIC;IAEJ,IAAIF,kBAAkBC,QAAQ;QAC5BC,OAAQ,MAAMH,IAAII,OAAO,CAACC,QAAQ,CAAC;YACjCC,IAAIJ;YACJK,YAAYN;QACd;IACF;IAEA,IAAI,CAACE,MAAM;QACT,MAAM,IAAInB,SAAS,0CAA0C,KAAK,MAAM;IAC1E;IAEA,IAAIU,OAAO;QACTM,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;YACvBD;YACAI;YACAC;YACAC;YACAU,SAAS;YACTC,eAAeV,IAAIU,aAAa;QAClC;IACF;IAEA,IAAI,CAACjB,gBAAgB;QACnB,MAAM,IAAIT,SAAS,+BAA+B,KAAK,MAAM;IAC/D;IAEA,IAAI,CAACY,QAAQ,CAACA,MAAMe,MAAM;QACxB,MAAM,IAAI3B,SAAS,oCAAoC,KAAK,MAAM;IACpE;IAEA,IAAIU,OAAO;QACTM,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;YACvBkB,UAAUhB,KAAKiB,IAAI;YACnBC,UAAUlB,KAAKe,IAAI,CAACI,MAAM;YAC1BN,SAAS;YACTO,UAAUpB,KAAKqB,QAAQ;QACzB;IACF;IAEA,MAAMC,mBAAmBlB,IAAII,OAAO,CAACe,MAAM,CAACC,WAAW,CAACC,IAAI,CAC1D,CAAC,EAAEC,IAAI,EAAE,GAAKA,SAAS7B;IAGzB,IAAI,CAACyB,kBAAkB;QACrB,IAAI,CAACzB,gBAAgB;YACnB,MAAM,IAAIT,SAAS,+BAA+B,KAAK,MAAM;QAC/D;QACA,MAAM,IAAIA,SAAS,CAAC,qBAAqB,EAAES,eAAe,UAAU,CAAC,EAAE,KAAK,MAAM;IACpF;IAEA,oCAAoC;IACpC,MAAM8B,iBACJL,iBAAiBM,KAAK,EAAEC,QAAQ,CAAC,uBAAuB,EAAEF,kBAAkB,EAAE;IAEhF,kDAAkD;IAClD,MAAMG,mBAAmBzC,wBAAwB;QAC/C0C,QAAQT,iBAAiBU,eAAe,IAAI,EAAE;IAChD;IAEA,sBAAsB;IACtB,IAAIC;IACJ,IAAIhC,WAAW,OAAO;QACpB,MAAMiC,UAAU,MAAM5C,SAAS;YAC7ByB,MAAMf,KAAKe,IAAI;YACfX;QACF;QAEA,gBAAgB;QAChB,IAAIN,SAASoC,QAAQf,MAAM,GAAG,GAAG;YAC/Bf,IAAII,OAAO,CAACI,MAAM,CAACuB,IAAI,CAAC;gBACtBC,UAAUF,OAAO,CAAC,EAAE;gBACpBG,KAAK;YACP;YACAjC,IAAII,OAAO,CAACI,MAAM,CAACuB,IAAI,CAAC;gBACtBE,KAAK;gBACLC,MAAMJ,QAAQK,GAAG,CAAC,CAACC,KAAKC,IAAO,CAAA;wBAC7BC,SAASF,IAAIE,OAAO;wBACpBC,eAAeH,IAAIG,aAAa;wBAChCC,sBAAsBJ,IAAII,oBAAoB;wBAC9CC,8BAA8BL,IAAIK,4BAA4B;wBAC9DC,OAAOL;wBACPM,OAAOP,IAAIO,KAAK;oBAClB,CAAA;YACF;QACF;QAEAd,YAAYC;QAEZ,qBAAqB;QACrBD,YAAYA,UACTM,GAAG,CAAC,CAACS;YACJ,MAAMC,cAAcxD,gBAAgB;gBAClCsB,MAAMiC;gBACNjB,QAAQT,iBAAiBU,eAAe,IAAI,EAAE;gBAC9CF;gBACA1B;YACF;YACA,OAAO6C,eAAe,CAAC;QACzB,GACCC,MAAM,CAAC,CAACF,MAAQA,OAAOG,OAAOC,IAAI,CAACJ,KAAK7B,MAAM,GAAG;QAEpD,wBAAwB;QACxB,IAAIrB,SAASmC,UAAUd,MAAM,GAAG,GAAG;YACjCf,IAAII,OAAO,CAACI,MAAM,CAACuB,IAAI,CAAC;gBACtBE,KAAK;gBACLC,MAAML,UAAUM,GAAG,CAAC,CAACC,KAAKC,IAAO,CAAA;wBAC/BE,eAAeH,IAAIG,aAAa;wBAChCU,oBAAoBb,IAAIa,kBAAkB;wBAC1CC,mBAAmBd,IAAIc,iBAAiB;wBACxCC,UAAU,WAAWf;wBACrBM,OAAOL;wBACPM,OAAOP,IAAIO,KAAK;oBAClB,CAAA;YACF;QACF;QAEA,IAAIjD,OAAO;YACTM,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;gBACvB0D,eAAevB,UAAUd,MAAM;gBAC/BN,SAAS;gBACT4C,cAAcvB,QAAQf,MAAM;YAC9B;YAEA,6CAA6C;YAC7C,IAAIe,QAAQf,MAAM,GAAG,KAAKc,UAAUd,MAAM,GAAG,GAAG;gBAC9Cf,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;oBACvBe,SAAS;oBACT6C,KAAKP,OAAOC,IAAI,CAAClB,OAAO,CAAC,EAAE,IAAI,CAAC,GAAGgB,MAAM,CAAC,CAACS,IAAMA,EAAEC,QAAQ,CAAC;oBAC5DX,aAAaY,KAAKC,SAAS,CAAC7B,SAAS,CAAC,EAAE,EAAE,MAAM;gBAClD;YACF;QACF;IACF,OAAO;QACLA,YAAY1C,UAAU;YAAEwB,MAAMf,KAAKe,IAAI;YAAEX;QAAI;IAC/C;IAEA,IAAIN,OAAO;QACTM,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;YACvBe,SAAS,CAAC,OAAO,EAAEoB,UAAUd,MAAM,CAAC,gBAAgB,EAAElB,OAAO,KAAK,CAAC;QACrE;QACA,IAAIgC,UAAUd,MAAM,GAAG,GAAG;YACxBf,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;gBACvBkD,KAAKf,SAAS,CAAC,EAAE;gBACjBpB,SAAS;YACX;QACF;IACF;IAEA,4CAA4C;IAC5C,IAAIc,eAAeR,MAAM,GAAG,GAAG;QAC7Bc,YAAYA,UAAUM,GAAG,CAAC,CAACS,MAAQxD,qBAAqBwD,KAAKrB;IAC/D;IAEA,IAAI7B,OAAO;QACTM,IAAII,OAAO,CAACI,MAAM,CAACd,KAAK,CAAC;YACvBF;YACA4D,eAAevB,UAAUd,MAAM;YAC/BN,SAAS;QACX;IACF;IAEA,yBAAyB;IACzB,MAAMkD,YAAYrE,2BAA2B;QAC3CE;QACAG;IACF;IAEA,sCAAsC;IACtC,MAAMiE,SAAS,MAAMD,UAAUE,aAAa,CAAC;QAC3CpE;QACAoC;QACA/B;QACAC;QACAC;QACAG;IACF;IAEA,IAAIT,OAAO;QACTM,IAAII,OAAO,CAACI,MAAM,CAACuB,IAAI,CAAC;YACtB+B,QAAQF,OAAOE,MAAM,CAAC/C,MAAM;YAC5BgD,UAAUH,OAAOG,QAAQ;YACzBtD,SAAS;YACTuD,OAAOJ,OAAOI,KAAK;YACnBC,SAASL,OAAOK,OAAO;QACzB;IACF;IAEA,OAAOL;AACT,EAAC"}