{"version":3,"sources":["../../src/export/createExport.ts"],"sourcesContent":["/* eslint-disable perfectionist/sort-objects */\nimport type { PayloadRequest, Sort, TypedUser, Where } from 'payload'\n\nimport { stringify } from 'csv-stringify/sync'\nimport { APIError } from 'payload'\nimport { Readable } from 'stream'\n\nimport { buildDisabledFieldRegex } from '../utilities/buildDisabledFieldRegex.js'\nimport { flattenObject } from '../utilities/flattenObject.js'\nimport { getExportFieldFunctions } from '../utilities/getExportFieldFunctions.js'\nimport { getFilename } from '../utilities/getFilename.js'\nimport { getSchemaColumns, mergeColumns } from '../utilities/getSchemaColumns.js'\nimport { getSelect } from '../utilities/getSelect.js'\nimport { validateLimitValue } from '../utilities/validateLimitValue.js'\nimport { createExportBatchProcessor, type ExportFindArgs } from './batchProcessor.js'\n\nexport type Export = {\n  /**\n   * Number of documents to process in each batch during export\n   * @default 100\n   */\n  batchSize?: number\n  collectionSlug: string\n  /**\n   * If true, enables debug logging\n   */\n  debug?: boolean\n  drafts?: 'no' | 'yes'\n  exportsCollection: string\n  fields?: string[]\n  format: 'csv' | 'json'\n  globals?: string[]\n  id: number | string\n  limit?: number\n  locale?: string\n  name: string\n  page?: number\n  slug: string\n  sort: Sort\n  userCollection: string\n  userID: number | string\n  where?: Where\n}\n\nexport type CreateExportArgs = {\n  /**\n   * If true, stream the file instead of saving it\n   */\n  download?: boolean\n  req: PayloadRequest\n} & Export\n\nexport const createExport = async (args: CreateExportArgs) => {\n  const {\n    id,\n    name: nameArg,\n    batchSize = 100,\n    collectionSlug,\n    debug = false,\n    download,\n    drafts: draftsFromInput,\n    exportsCollection,\n    fields,\n    format,\n    limit: incomingLimit,\n    locale: localeFromInput,\n    page,\n    req,\n    sort,\n    userCollection,\n    userID,\n    where: whereFromInput = {},\n  } = args\n  const { locale: localeFromReq, payload } = req\n\n  if (debug) {\n    req.payload.logger.debug({\n      message: 'Starting export process with args:',\n      collectionSlug,\n      draft: draftsFromInput,\n      fields,\n      format,\n    })\n  }\n\n  const locale = localeFromInput ?? localeFromReq\n  const collectionConfig = payload.config.collections.find(({ slug }) => slug === collectionSlug)\n\n  if (!collectionConfig) {\n    throw new APIError(`Collection with slug ${collectionSlug} not found.`)\n  }\n\n  let user: TypedUser | undefined\n\n  if (userCollection && userID) {\n    user = (await req.payload.findByID({\n      id: userID,\n      collection: userCollection,\n      overrideAccess: true,\n    })) as TypedUser\n  }\n\n  if (!user && req.user) {\n    user = req?.user?.id ? req.user : req?.user?.user\n  }\n\n  if (!user) {\n    throw new APIError('User authentication is required to create exports.')\n  }\n\n  const draft = draftsFromInput === 'yes'\n  const hasVersions = Boolean(collectionConfig.versions)\n\n  // Only filter by _status for versioned collections\n  const publishedWhere: Where = hasVersions ? { _status: { equals: 'published' } } : {}\n\n  const where: Where = {\n    and: [whereFromInput, draft ? {} : publishedWhere],\n  }\n\n  const name = `${nameArg ?? `${getFilename()}-${collectionSlug}`}.${format}`\n  const isCSV = format === 'csv'\n  const select = Array.isArray(fields) && fields.length > 0 ? getSelect(fields) : undefined\n\n  if (debug) {\n    req.payload.logger.debug({ message: 'Export configuration:', name, isCSV, locale })\n  }\n\n  const hardLimit =\n    typeof incomingLimit === 'number' && incomingLimit > 0 ? incomingLimit : undefined\n\n  // Try to count documents - if access is denied, treat as 0 documents\n  let totalDocs = 0\n  let accessDenied = false\n  try {\n    const countResult = await payload.count({\n      collection: collectionSlug,\n      user,\n      locale,\n      overrideAccess: false,\n    })\n    totalDocs = countResult.totalDocs\n  } catch (error) {\n    // Access denied - user can't read from this collection\n    // We'll create an empty export file\n    accessDenied = true\n    if (debug) {\n      req.payload.logger.debug({\n        message: 'Access denied for collection, creating empty export',\n        collectionSlug,\n      })\n    }\n  }\n\n  const totalPages = Math.max(1, Math.ceil(totalDocs / batchSize))\n  const requestedPage = page || 1\n  const adjustedPage = requestedPage > totalPages ? 1 : requestedPage\n\n  const findArgs = {\n    collection: collectionSlug,\n    depth: 1,\n    draft,\n    limit: batchSize,\n    locale,\n    overrideAccess: false,\n    page: 0, // The page will be incremented manually in the loop\n    select,\n    sort,\n    user,\n    where,\n  }\n\n  if (debug) {\n    req.payload.logger.debug({ message: 'Find arguments:', findArgs })\n  }\n\n  const toCSVFunctions = getExportFieldFunctions({\n    fields: collectionConfig.flattenedFields,\n  })\n\n  const disabledFields =\n    collectionConfig.admin?.custom?.['plugin-import-export']?.disabledFields ?? []\n\n  const disabledRegexes: RegExp[] = disabledFields.map(buildDisabledFieldRegex)\n\n  const filterDisabledCSV = (row: Record<string, unknown>): Record<string, unknown> => {\n    const filtered: Record<string, unknown> = {}\n\n    for (const [key, value] of Object.entries(row)) {\n      const isDisabled = disabledRegexes.some((regex) => regex.test(key))\n      if (!isDisabled) {\n        filtered[key] = value\n      }\n    }\n\n    return filtered\n  }\n\n  const filterDisabledJSON = (doc: any, parentPath = ''): any => {\n    if (Array.isArray(doc)) {\n      return doc.map((item) => filterDisabledJSON(item, parentPath))\n    }\n\n    if (typeof doc !== 'object' || doc === null) {\n      return doc\n    }\n\n    const filtered: Record<string, any> = {}\n    for (const [key, value] of Object.entries(doc)) {\n      const currentPath = parentPath ? `${parentPath}.${key}` : key\n\n      // Only remove if this exact path is disabled\n      const isDisabled = disabledFields.includes(currentPath)\n\n      if (!isDisabled) {\n        filtered[key] = filterDisabledJSON(value, currentPath)\n      }\n    }\n\n    return filtered\n  }\n\n  if (download) {\n    const limitErrorMsg = validateLimitValue(incomingLimit, req.t)\n    if (limitErrorMsg) {\n      throw new APIError(limitErrorMsg)\n    }\n\n    // Get schema-based columns first (provides base ordering and handles empty exports)\n    let schemaColumns: string[] = []\n    if (isCSV) {\n      const localeCodes =\n        locale === 'all' && payload.config.localization\n          ? payload.config.localization.localeCodes\n          : undefined\n\n      schemaColumns = getSchemaColumns({\n        collectionConfig,\n        disabledFields,\n        fields,\n        locale,\n        localeCodes,\n      })\n\n      if (debug) {\n        req.payload.logger.debug({\n          columnCount: schemaColumns.length,\n          msg: 'Schema-based column inference complete',\n        })\n      }\n    }\n\n    // allColumns will be finalized after first batch (schema + data columns merged)\n    let allColumns: string[] = []\n    let columnsFinalized = false\n\n    const encoder = new TextEncoder()\n    let isFirstBatch = true\n    let streamPage = adjustedPage\n    let fetched = 0\n    const maxDocs = typeof hardLimit === 'number' ? hardLimit : Number.POSITIVE_INFINITY\n\n    const stream = new Readable({\n      async read() {\n        const remaining = Math.max(0, maxDocs - fetched)\n\n        if (remaining === 0) {\n          if (!isCSV) {\n            // If first batch with no remaining, output empty array; otherwise just close\n            this.push(encoder.encode(isFirstBatch ? '[]' : ']'))\n          }\n          this.push(null)\n          return\n        }\n\n        const result = await payload.find({\n          ...findArgs,\n          page: streamPage,\n          limit: Math.min(batchSize, remaining),\n        })\n\n        if (debug) {\n          req.payload.logger.debug(`Streaming batch ${streamPage} with ${result.docs.length} docs`)\n        }\n\n        if (result.docs.length === 0) {\n          // Close JSON array properly if JSON\n          if (!isCSV) {\n            // If first batch with no docs, output empty array; otherwise just close\n            this.push(encoder.encode(isFirstBatch ? '[]' : ']'))\n          }\n          this.push(null)\n          return\n        }\n\n        if (isCSV) {\n          // --- CSV Streaming ---\n          const batchRows = result.docs.map((doc) =>\n            filterDisabledCSV(flattenObject({ doc, fields, toCSVFunctions })),\n          )\n\n          // On first batch, discover additional columns from data and merge with schema\n          if (!columnsFinalized) {\n            const dataColumns: string[] = []\n            const seenCols = new Set<string>()\n            for (const row of batchRows) {\n              for (const key of Object.keys(row)) {\n                if (!seenCols.has(key)) {\n                  seenCols.add(key)\n                  dataColumns.push(key)\n                }\n              }\n            }\n            // Merge schema columns with data-discovered columns\n            allColumns = mergeColumns(schemaColumns, dataColumns)\n            columnsFinalized = true\n\n            if (debug) {\n              req.payload.logger.debug({\n                dataColumnsCount: dataColumns.length,\n                finalColumnsCount: allColumns.length,\n                msg: 'Merged schema and data columns',\n              })\n            }\n          }\n\n          const paddedRows = batchRows.map((row) => {\n            const fullRow: Record<string, unknown> = {}\n            for (const col of allColumns) {\n              fullRow[col] = row[col] ?? ''\n            }\n            return fullRow\n          })\n\n          const csvString = stringify(paddedRows, {\n            header: isFirstBatch,\n            columns: allColumns,\n          })\n\n          this.push(encoder.encode(csvString))\n        } else {\n          // --- JSON Streaming ---\n          const batchRows = result.docs.map((doc) => filterDisabledJSON(doc))\n\n          // Convert each filtered/flattened row into JSON string\n          const batchJSON = batchRows.map((row) => JSON.stringify(row)).join(',')\n\n          if (isFirstBatch) {\n            this.push(encoder.encode('[' + batchJSON))\n          } else {\n            this.push(encoder.encode(',' + batchJSON))\n          }\n        }\n\n        fetched += result.docs.length\n        isFirstBatch = false\n        streamPage += 1 // Increment stream page for the next batch\n\n        if (!result.hasNextPage || fetched >= maxDocs) {\n          if (debug) {\n            req.payload.logger.debug('Stream complete - no more pages')\n          }\n          if (!isCSV) {\n            this.push(encoder.encode(']'))\n          }\n          this.push(null) // End the stream\n        }\n      },\n    })\n\n    return new Response(Readable.toWeb(stream) as ReadableStream, {\n      headers: {\n        'Content-Disposition': `attachment; filename=\"${name}\"`,\n        'Content-Type': isCSV ? 'text/csv' : 'application/json',\n      },\n    })\n  }\n\n  // Non-download path (buffered export)\n  if (debug) {\n    req.payload.logger.debug('Starting file generation')\n  }\n\n  // Create export batch processor\n  const processor = createExportBatchProcessor({ batchSize, debug })\n\n  // Transform function based on format\n  const transformDoc = (doc: unknown) =>\n    isCSV\n      ? filterDisabledCSV(flattenObject({ doc, fields, toCSVFunctions }))\n      : filterDisabledJSON(doc)\n\n  // Skip fetching if access was denied - we'll create an empty export\n  let exportResult = {\n    columns: [] as string[],\n    docs: [] as Record<string, unknown>[],\n    fetchedCount: 0,\n  }\n\n  if (!accessDenied) {\n    exportResult = await processor.processExport({\n      collectionSlug,\n      findArgs: findArgs as ExportFindArgs,\n      format,\n      maxDocs: typeof hardLimit === 'number' ? hardLimit : Number.POSITIVE_INFINITY,\n      req,\n      startPage: adjustedPage,\n      transformDoc,\n    })\n  }\n\n  const { columns: dataColumns, docs: rows } = exportResult\n  const outputData: string[] = []\n\n  // Prepare final output\n  if (isCSV) {\n    // Get schema-based columns for consistent ordering\n    const localeCodes =\n      locale === 'all' && payload.config.localization\n        ? payload.config.localization.localeCodes\n        : undefined\n\n    const schemaColumns = getSchemaColumns({\n      collectionConfig,\n      disabledFields,\n      fields,\n      locale,\n      localeCodes,\n    })\n\n    // Merge schema columns with data-discovered columns\n    // Schema provides ordering, data provides additional columns (e.g., array indices > 0)\n    const finalColumns = mergeColumns(schemaColumns, dataColumns)\n\n    const paddedRows = rows.map((row) => {\n      const fullRow: Record<string, unknown> = {}\n      for (const col of finalColumns) {\n        fullRow[col] = row[col] ?? ''\n      }\n      return fullRow\n    })\n\n    // Always output CSV with header, even if empty\n    outputData.push(\n      stringify(paddedRows, {\n        header: true,\n        columns: finalColumns,\n      }),\n    )\n  } else {\n    // JSON format\n    outputData.push(rows.map((doc) => JSON.stringify(doc)).join(',\\n'))\n  }\n\n  // Ensure we always have valid content for the file\n  // For JSON, empty exports produce \"[]\"\n  // For CSV, if completely empty (no columns, no rows), produce at least a newline to ensure file creation\n  const content = format === 'json' ? `[${outputData.join(',')}]` : outputData.join('')\n  const buffer = Buffer.from(content.length > 0 ? content : '\\n')\n  if (debug) {\n    req.payload.logger.debug(`${format} file generation complete`)\n  }\n\n  if (!id) {\n    if (debug) {\n      req.payload.logger.debug('Creating new export file')\n    }\n    req.file = {\n      name,\n      data: buffer,\n      mimetype: isCSV ? 'text/csv' : 'application/json',\n      size: buffer.length,\n    }\n  } else {\n    if (debug) {\n      req.payload.logger.debug(`Updating existing export with id: ${id}`)\n    }\n    await req.payload.update({\n      id,\n      collection: exportsCollection,\n      data: {},\n      file: {\n        name,\n        data: buffer,\n        mimetype: isCSV ? 'text/csv' : 'application/json',\n        size: buffer.length,\n      },\n      // Override access only here so that we can be sure the export collection itself is updated as expected\n      overrideAccess: true,\n      req,\n    })\n  }\n  if (debug) {\n    req.payload.logger.debug('Export process completed successfully')\n  }\n}\n"],"names":["stringify","APIError","Readable","buildDisabledFieldRegex","flattenObject","getExportFieldFunctions","getFilename","getSchemaColumns","mergeColumns","getSelect","validateLimitValue","createExportBatchProcessor","createExport","args","id","name","nameArg","batchSize","collectionSlug","debug","download","drafts","draftsFromInput","exportsCollection","fields","format","limit","incomingLimit","locale","localeFromInput","page","req","sort","userCollection","userID","where","whereFromInput","localeFromReq","payload","logger","message","draft","collectionConfig","config","collections","find","slug","user","findByID","collection","overrideAccess","hasVersions","Boolean","versions","publishedWhere","_status","equals","and","isCSV","select","Array","isArray","length","undefined","hardLimit","totalDocs","accessDenied","countResult","count","error","totalPages","Math","max","ceil","requestedPage","adjustedPage","findArgs","depth","toCSVFunctions","flattenedFields","disabledFields","admin","custom","disabledRegexes","map","filterDisabledCSV","row","filtered","key","value","Object","entries","isDisabled","some","regex","test","filterDisabledJSON","doc","parentPath","item","currentPath","includes","limitErrorMsg","t","schemaColumns","localeCodes","localization","columnCount","msg","allColumns","columnsFinalized","encoder","TextEncoder","isFirstBatch","streamPage","fetched","maxDocs","Number","POSITIVE_INFINITY","stream","read","remaining","push","encode","result","min","docs","batchRows","dataColumns","seenCols","Set","keys","has","add","dataColumnsCount","finalColumnsCount","paddedRows","fullRow","col","csvString","header","columns","batchJSON","JSON","join","hasNextPage","Response","toWeb","headers","processor","transformDoc","exportResult","fetchedCount","processExport","startPage","rows","outputData","finalColumns","content","buffer","Buffer","from","file","data","mimetype","size","update"],"mappings":"AAAA,6CAA6C,GAG7C,SAASA,SAAS,QAAQ,qBAAoB;AAC9C,SAASC,QAAQ,QAAQ,UAAS;AAClC,SAASC,QAAQ,QAAQ,SAAQ;AAEjC,SAASC,uBAAuB,QAAQ,0CAAyC;AACjF,SAASC,aAAa,QAAQ,gCAA+B;AAC7D,SAASC,uBAAuB,QAAQ,0CAAyC;AACjF,SAASC,WAAW,QAAQ,8BAA6B;AACzD,SAASC,gBAAgB,EAAEC,YAAY,QAAQ,mCAAkC;AACjF,SAASC,SAAS,QAAQ,4BAA2B;AACrD,SAASC,kBAAkB,QAAQ,qCAAoC;AACvE,SAASC,0BAA0B,QAA6B,sBAAqB;AAsCrF,OAAO,MAAMC,eAAe,OAAOC;IACjC,MAAM,EACJC,EAAE,EACFC,MAAMC,OAAO,EACbC,YAAY,GAAG,EACfC,cAAc,EACdC,QAAQ,KAAK,EACbC,QAAQ,EACRC,QAAQC,eAAe,EACvBC,iBAAiB,EACjBC,MAAM,EACNC,MAAM,EACNC,OAAOC,aAAa,EACpBC,QAAQC,eAAe,EACvBC,IAAI,EACJC,GAAG,EACHC,IAAI,EACJC,cAAc,EACdC,MAAM,EACNC,OAAOC,iBAAiB,CAAC,CAAC,EAC3B,GAAGvB;IACJ,MAAM,EAAEe,QAAQS,aAAa,EAAEC,OAAO,EAAE,GAAGP;IAE3C,IAAIZ,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;YACvBqB,SAAS;YACTtB;YACAuB,OAAOnB;YACPE;YACAC;QACF;IACF;IAEA,MAAMG,SAASC,mBAAmBQ;IAClC,MAAMK,mBAAmBJ,QAAQK,MAAM,CAACC,WAAW,CAACC,IAAI,CAAC,CAAC,EAAEC,IAAI,EAAE,GAAKA,SAAS5B;IAEhF,IAAI,CAACwB,kBAAkB;QACrB,MAAM,IAAIzC,SAAS,CAAC,qBAAqB,EAAEiB,eAAe,WAAW,CAAC;IACxE;IAEA,IAAI6B;IAEJ,IAAId,kBAAkBC,QAAQ;QAC5Ba,OAAQ,MAAMhB,IAAIO,OAAO,CAACU,QAAQ,CAAC;YACjClC,IAAIoB;YACJe,YAAYhB;YACZiB,gBAAgB;QAClB;IACF;IAEA,IAAI,CAACH,QAAQhB,IAAIgB,IAAI,EAAE;QACrBA,OAAOhB,KAAKgB,MAAMjC,KAAKiB,IAAIgB,IAAI,GAAGhB,KAAKgB,MAAMA;IAC/C;IAEA,IAAI,CAACA,MAAM;QACT,MAAM,IAAI9C,SAAS;IACrB;IAEA,MAAMwC,QAAQnB,oBAAoB;IAClC,MAAM6B,cAAcC,QAAQV,iBAAiBW,QAAQ;IAErD,mDAAmD;IACnD,MAAMC,iBAAwBH,cAAc;QAAEI,SAAS;YAAEC,QAAQ;QAAY;IAAE,IAAI,CAAC;IAEpF,MAAMrB,QAAe;QACnBsB,KAAK;YAACrB;YAAgBK,QAAQ,CAAC,IAAIa;SAAe;IACpD;IAEA,MAAMvC,OAAO,GAAGC,WAAW,GAAGV,cAAc,CAAC,EAAEY,gBAAgB,CAAC,CAAC,EAAEO,QAAQ;IAC3E,MAAMiC,QAAQjC,WAAW;IACzB,MAAMkC,SAASC,MAAMC,OAAO,CAACrC,WAAWA,OAAOsC,MAAM,GAAG,IAAIrD,UAAUe,UAAUuC;IAEhF,IAAI5C,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;YAAEqB,SAAS;YAAyBzB;YAAM2C;YAAO9B;QAAO;IACnF;IAEA,MAAMoC,YACJ,OAAOrC,kBAAkB,YAAYA,gBAAgB,IAAIA,gBAAgBoC;IAE3E,qEAAqE;IACrE,IAAIE,YAAY;IAChB,IAAIC,eAAe;IACnB,IAAI;QACF,MAAMC,cAAc,MAAM7B,QAAQ8B,KAAK,CAAC;YACtCnB,YAAY/B;YACZ6B;YACAnB;YACAsB,gBAAgB;QAClB;QACAe,YAAYE,YAAYF,SAAS;IACnC,EAAE,OAAOI,OAAO;QACd,uDAAuD;QACvD,oCAAoC;QACpCH,eAAe;QACf,IAAI/C,OAAO;YACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;gBACvBqB,SAAS;gBACTtB;YACF;QACF;IACF;IAEA,MAAMoD,aAAaC,KAAKC,GAAG,CAAC,GAAGD,KAAKE,IAAI,CAACR,YAAYhD;IACrD,MAAMyD,gBAAgB5C,QAAQ;IAC9B,MAAM6C,eAAeD,gBAAgBJ,aAAa,IAAII;IAEtD,MAAME,WAAW;QACf3B,YAAY/B;QACZ2D,OAAO;QACPpC;QACAf,OAAOT;QACPW;QACAsB,gBAAgB;QAChBpB,MAAM;QACN6B;QACA3B;QACAe;QACAZ;IACF;IAEA,IAAIhB,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;YAAEqB,SAAS;YAAmBoC;QAAS;IAClE;IAEA,MAAME,iBAAiBzE,wBAAwB;QAC7CmB,QAAQkB,iBAAiBqC,eAAe;IAC1C;IAEA,MAAMC,iBACJtC,iBAAiBuC,KAAK,EAAEC,QAAQ,CAAC,uBAAuB,EAAEF,kBAAkB,EAAE;IAEhF,MAAMG,kBAA4BH,eAAeI,GAAG,CAACjF;IAErD,MAAMkF,oBAAoB,CAACC;QACzB,MAAMC,WAAoC,CAAC;QAE3C,KAAK,MAAM,CAACC,KAAKC,MAAM,IAAIC,OAAOC,OAAO,CAACL,KAAM;YAC9C,MAAMM,aAAaT,gBAAgBU,IAAI,CAAC,CAACC,QAAUA,MAAMC,IAAI,CAACP;YAC9D,IAAI,CAACI,YAAY;gBACfL,QAAQ,CAACC,IAAI,GAAGC;YAClB;QACF;QAEA,OAAOF;IACT;IAEA,MAAMS,qBAAqB,CAACC,KAAUC,aAAa,EAAE;QACnD,IAAItC,MAAMC,OAAO,CAACoC,MAAM;YACtB,OAAOA,IAAIb,GAAG,CAAC,CAACe,OAASH,mBAAmBG,MAAMD;QACpD;QAEA,IAAI,OAAOD,QAAQ,YAAYA,QAAQ,MAAM;YAC3C,OAAOA;QACT;QAEA,MAAMV,WAAgC,CAAC;QACvC,KAAK,MAAM,CAACC,KAAKC,MAAM,IAAIC,OAAOC,OAAO,CAACM,KAAM;YAC9C,MAAMG,cAAcF,aAAa,GAAGA,WAAW,CAAC,EAAEV,KAAK,GAAGA;YAE1D,6CAA6C;YAC7C,MAAMI,aAAaZ,eAAeqB,QAAQ,CAACD;YAE3C,IAAI,CAACR,YAAY;gBACfL,QAAQ,CAACC,IAAI,GAAGQ,mBAAmBP,OAAOW;YAC5C;QACF;QAEA,OAAOb;IACT;IAEA,IAAInE,UAAU;QACZ,MAAMkF,gBAAgB5F,mBAAmBiB,eAAeI,IAAIwE,CAAC;QAC7D,IAAID,eAAe;YACjB,MAAM,IAAIrG,SAASqG;QACrB;QAEA,oFAAoF;QACpF,IAAIE,gBAA0B,EAAE;QAChC,IAAI9C,OAAO;YACT,MAAM+C,cACJ7E,WAAW,SAASU,QAAQK,MAAM,CAAC+D,YAAY,GAC3CpE,QAAQK,MAAM,CAAC+D,YAAY,CAACD,WAAW,GACvC1C;YAENyC,gBAAgBjG,iBAAiB;gBAC/BmC;gBACAsC;gBACAxD;gBACAI;gBACA6E;YACF;YAEA,IAAItF,OAAO;gBACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;oBACvBwF,aAAaH,cAAc1C,MAAM;oBACjC8C,KAAK;gBACP;YACF;QACF;QAEA,gFAAgF;QAChF,IAAIC,aAAuB,EAAE;QAC7B,IAAIC,mBAAmB;QAEvB,MAAMC,UAAU,IAAIC;QACpB,IAAIC,eAAe;QACnB,IAAIC,aAAavC;QACjB,IAAIwC,UAAU;QACd,MAAMC,UAAU,OAAOpD,cAAc,WAAWA,YAAYqD,OAAOC,iBAAiB;QAEpF,MAAMC,SAAS,IAAIrH,SAAS;YAC1B,MAAMsH;gBACJ,MAAMC,YAAYlD,KAAKC,GAAG,CAAC,GAAG4C,UAAUD;gBAExC,IAAIM,cAAc,GAAG;oBACnB,IAAI,CAAC/D,OAAO;wBACV,6EAA6E;wBAC7E,IAAI,CAACgE,IAAI,CAACX,QAAQY,MAAM,CAACV,eAAe,OAAO;oBACjD;oBACA,IAAI,CAACS,IAAI,CAAC;oBACV;gBACF;gBAEA,MAAME,SAAS,MAAMtF,QAAQO,IAAI,CAAC;oBAChC,GAAG+B,QAAQ;oBACX9C,MAAMoF;oBACNxF,OAAO6C,KAAKsD,GAAG,CAAC5G,WAAWwG;gBAC7B;gBAEA,IAAItG,OAAO;oBACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC,CAAC,gBAAgB,EAAE+F,WAAW,MAAM,EAAEU,OAAOE,IAAI,CAAChE,MAAM,CAAC,KAAK,CAAC;gBAC1F;gBAEA,IAAI8D,OAAOE,IAAI,CAAChE,MAAM,KAAK,GAAG;oBAC5B,oCAAoC;oBACpC,IAAI,CAACJ,OAAO;wBACV,wEAAwE;wBACxE,IAAI,CAACgE,IAAI,CAACX,QAAQY,MAAM,CAACV,eAAe,OAAO;oBACjD;oBACA,IAAI,CAACS,IAAI,CAAC;oBACV;gBACF;gBAEA,IAAIhE,OAAO;oBACT,wBAAwB;oBACxB,MAAMqE,YAAYH,OAAOE,IAAI,CAAC1C,GAAG,CAAC,CAACa,MACjCZ,kBAAkBjF,cAAc;4BAAE6F;4BAAKzE;4BAAQsD;wBAAe;oBAGhE,8EAA8E;oBAC9E,IAAI,CAACgC,kBAAkB;wBACrB,MAAMkB,cAAwB,EAAE;wBAChC,MAAMC,WAAW,IAAIC;wBACrB,KAAK,MAAM5C,OAAOyC,UAAW;4BAC3B,KAAK,MAAMvC,OAAOE,OAAOyC,IAAI,CAAC7C,KAAM;gCAClC,IAAI,CAAC2C,SAASG,GAAG,CAAC5C,MAAM;oCACtByC,SAASI,GAAG,CAAC7C;oCACbwC,YAAYN,IAAI,CAAClC;gCACnB;4BACF;wBACF;wBACA,oDAAoD;wBACpDqB,aAAarG,aAAagG,eAAewB;wBACzClB,mBAAmB;wBAEnB,IAAI3F,OAAO;4BACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;gCACvBmH,kBAAkBN,YAAYlE,MAAM;gCACpCyE,mBAAmB1B,WAAW/C,MAAM;gCACpC8C,KAAK;4BACP;wBACF;oBACF;oBAEA,MAAM4B,aAAaT,UAAU3C,GAAG,CAAC,CAACE;wBAChC,MAAMmD,UAAmC,CAAC;wBAC1C,KAAK,MAAMC,OAAO7B,WAAY;4BAC5B4B,OAAO,CAACC,IAAI,GAAGpD,GAAG,CAACoD,IAAI,IAAI;wBAC7B;wBACA,OAAOD;oBACT;oBAEA,MAAME,YAAY3I,UAAUwI,YAAY;wBACtCI,QAAQ3B;wBACR4B,SAAShC;oBACX;oBAEA,IAAI,CAACa,IAAI,CAACX,QAAQY,MAAM,CAACgB;gBAC3B,OAAO;oBACL,yBAAyB;oBACzB,MAAMZ,YAAYH,OAAOE,IAAI,CAAC1C,GAAG,CAAC,CAACa,MAAQD,mBAAmBC;oBAE9D,uDAAuD;oBACvD,MAAM6C,YAAYf,UAAU3C,GAAG,CAAC,CAACE,MAAQyD,KAAK/I,SAAS,CAACsF,MAAM0D,IAAI,CAAC;oBAEnE,IAAI/B,cAAc;wBAChB,IAAI,CAACS,IAAI,CAACX,QAAQY,MAAM,CAAC,MAAMmB;oBACjC,OAAO;wBACL,IAAI,CAACpB,IAAI,CAACX,QAAQY,MAAM,CAAC,MAAMmB;oBACjC;gBACF;gBAEA3B,WAAWS,OAAOE,IAAI,CAAChE,MAAM;gBAC7BmD,eAAe;gBACfC,cAAc,GAAE,2CAA2C;gBAE3D,IAAI,CAACU,OAAOqB,WAAW,IAAI9B,WAAWC,SAAS;oBAC7C,IAAIjG,OAAO;wBACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;oBAC3B;oBACA,IAAI,CAACuC,OAAO;wBACV,IAAI,CAACgE,IAAI,CAACX,QAAQY,MAAM,CAAC;oBAC3B;oBACA,IAAI,CAACD,IAAI,CAAC,OAAM,iBAAiB;gBACnC;YACF;QACF;QAEA,OAAO,IAAIwB,SAAShJ,SAASiJ,KAAK,CAAC5B,SAA2B;YAC5D6B,SAAS;gBACP,uBAAuB,CAAC,sBAAsB,EAAErI,KAAK,CAAC,CAAC;gBACvD,gBAAgB2C,QAAQ,aAAa;YACvC;QACF;IACF;IAEA,sCAAsC;IACtC,IAAIvC,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;IAC3B;IAEA,gCAAgC;IAChC,MAAMkI,YAAY1I,2BAA2B;QAAEM;QAAWE;IAAM;IAEhE,qCAAqC;IACrC,MAAMmI,eAAe,CAACrD,MACpBvC,QACI2B,kBAAkBjF,cAAc;YAAE6F;YAAKzE;YAAQsD;QAAe,MAC9DkB,mBAAmBC;IAEzB,oEAAoE;IACpE,IAAIsD,eAAe;QACjBV,SAAS,EAAE;QACXf,MAAM,EAAE;QACR0B,cAAc;IAChB;IAEA,IAAI,CAACtF,cAAc;QACjBqF,eAAe,MAAMF,UAAUI,aAAa,CAAC;YAC3CvI;YACA0D,UAAUA;YACVnD;YACA2F,SAAS,OAAOpD,cAAc,WAAWA,YAAYqD,OAAOC,iBAAiB;YAC7EvF;YACA2H,WAAW/E;YACX2E;QACF;IACF;IAEA,MAAM,EAAET,SAASb,WAAW,EAAEF,MAAM6B,IAAI,EAAE,GAAGJ;IAC7C,MAAMK,aAAuB,EAAE;IAE/B,uBAAuB;IACvB,IAAIlG,OAAO;QACT,mDAAmD;QACnD,MAAM+C,cACJ7E,WAAW,SAASU,QAAQK,MAAM,CAAC+D,YAAY,GAC3CpE,QAAQK,MAAM,CAAC+D,YAAY,CAACD,WAAW,GACvC1C;QAEN,MAAMyC,gBAAgBjG,iBAAiB;YACrCmC;YACAsC;YACAxD;YACAI;YACA6E;QACF;QAEA,oDAAoD;QACpD,uFAAuF;QACvF,MAAMoD,eAAerJ,aAAagG,eAAewB;QAEjD,MAAMQ,aAAamB,KAAKvE,GAAG,CAAC,CAACE;YAC3B,MAAMmD,UAAmC,CAAC;YAC1C,KAAK,MAAMC,OAAOmB,aAAc;gBAC9BpB,OAAO,CAACC,IAAI,GAAGpD,GAAG,CAACoD,IAAI,IAAI;YAC7B;YACA,OAAOD;QACT;QAEA,+CAA+C;QAC/CmB,WAAWlC,IAAI,CACb1H,UAAUwI,YAAY;YACpBI,QAAQ;YACRC,SAASgB;QACX;IAEJ,OAAO;QACL,cAAc;QACdD,WAAWlC,IAAI,CAACiC,KAAKvE,GAAG,CAAC,CAACa,MAAQ8C,KAAK/I,SAAS,CAACiG,MAAM+C,IAAI,CAAC;IAC9D;IAEA,mDAAmD;IACnD,uCAAuC;IACvC,yGAAyG;IACzG,MAAMc,UAAUrI,WAAW,SAAS,CAAC,CAAC,EAAEmI,WAAWZ,IAAI,CAAC,KAAK,CAAC,CAAC,GAAGY,WAAWZ,IAAI,CAAC;IAClF,MAAMe,SAASC,OAAOC,IAAI,CAACH,QAAQhG,MAAM,GAAG,IAAIgG,UAAU;IAC1D,IAAI3I,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC,GAAGM,OAAO,yBAAyB,CAAC;IAC/D;IAEA,IAAI,CAACX,IAAI;QACP,IAAIK,OAAO;YACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;QAC3B;QACAY,IAAImI,IAAI,GAAG;YACTnJ;YACAoJ,MAAMJ;YACNK,UAAU1G,QAAQ,aAAa;YAC/B2G,MAAMN,OAAOjG,MAAM;QACrB;IACF,OAAO;QACL,IAAI3C,OAAO;YACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC,CAAC,kCAAkC,EAAEL,IAAI;QACpE;QACA,MAAMiB,IAAIO,OAAO,CAACgI,MAAM,CAAC;YACvBxJ;YACAmC,YAAY1B;YACZ4I,MAAM,CAAC;YACPD,MAAM;gBACJnJ;gBACAoJ,MAAMJ;gBACNK,UAAU1G,QAAQ,aAAa;gBAC/B2G,MAAMN,OAAOjG,MAAM;YACrB;YACA,uGAAuG;YACvGZ,gBAAgB;YAChBnB;QACF;IACF;IACA,IAAIZ,OAAO;QACTY,IAAIO,OAAO,CAACC,MAAM,CAACpB,KAAK,CAAC;IAC3B;AACF,EAAC"}